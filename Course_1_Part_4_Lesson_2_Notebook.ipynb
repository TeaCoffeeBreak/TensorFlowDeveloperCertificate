{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course 1 - Part 4 - Lesson 2 - Notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHm8hjM66jtmwI+UzGYYVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianHwang/TensorFlowDeveloperCertificate/blob/main/Course_1_Part_4_Lesson_2_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMl6D6Vg_6E2"
      },
      "source": [
        "# A Computer Vision Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOyb7g-rAReZ",
        "outputId": "73d8fafa-d903-482a-f806-8f469c1d33d9"
      },
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRFj0RnjAhlO"
      },
      "source": [
        "# Data : Fashion MNIST data\n",
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TehL0VU7BSVz"
      },
      "source": [
        "Question myself : what are foramt of mnist ? array ? tensor ????"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVYNahR0A1KV",
        "outputId": "02154ffe-4984-435c-ed6c-8621bb0412e7"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "qyBigrTUB3TA",
        "outputId": "a04472a2-2c5e-45f1-b55f-ae928543fc6b"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ubyqEAiCY4a"
      },
      "source": [
        "# normalizing\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZU8zxO7H9Z8"
      },
      "source": [
        "**Sequential**: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "**Flatten**: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
        "\n",
        " 'flatten' that 28,28 into a 784x1\n",
        " \n",
        "**Dense**: Adds a layer of neurons\n",
        "\n",
        "Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
        "\n",
        "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhmOxsbsC02z"
      },
      "source": [
        "# model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR1luYUrDcWd",
        "outputId": "98d9b921-121e-464b-e17e-465100a89297"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5017 - accuracy: 0.8225\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3742 - accuracy: 0.8643\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.8764\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3133 - accuracy: 0.8849\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2964 - accuracy: 0.8905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f972bdfc510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1cZ1ddVErpM",
        "outputId": "8901db7c-ad93-49d5-9415-f74d4cb9c2a1"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3641625940799713, 0.8679999709129333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAkeLvn8Fr3g"
      },
      "source": [
        "# Exploration Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF476B1YIZ9t",
        "outputId": "fab4204b-8268-4d0b-ee79-8871b618892f"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.2205060e-05 1.8803044e-08 1.9977605e-07 3.4983768e-07 2.7299550e-06 4.6467432e-03 5.5896203e-06 2.6840888e-02 2.1905253e-05 9.6845937e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba8pe7HOI0Na",
        "outputId": "57a1a5b0-b65a-4549-85c6-46ca09d9c0bd"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y_HJtYnSJs6M",
        "outputId": "d75e4a79-bd2f-442d-e6e9-31039a0939c0"
      },
      "source": [
        "minst = tf.keras.datasets.mnist\n",
        "(traning_images, traning_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "traning_images = traning_images / 255.0\n",
        "traning_labels = traning_labels / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer= 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(traning_images, traning_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images,test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[10])\n",
        "print(test_labels[10])\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(test_images[10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0019\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 5.1027e-08\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4253e-08\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 4.3986e-09\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.9272e-09\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 9.3181e-10\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 5.3843e-10\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 3.0796e-10\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8676e-10\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.2120e-10\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 8.7420e-11\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 6.7552e-11\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 4.7684e-11\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 3.1789e-11\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.7815e-11\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 2.3842e-11\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 2.1855e-11\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7881e-11\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7881e-11\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7881e-11\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5895e-11\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3908e-11\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.3908e-11\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 7.9473e-12\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 7.9473e-12\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 7.9473e-12\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 7.9473e-12\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 7.9473e-12\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 5.9605e-12\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 5.9605e-12\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 30929.3320\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f971d015e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB2DvXFbNUcg"
      },
      "source": [
        "# call back "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I8NLOuwP3Vr",
        "outputId": "a9420610-4fe6-4cbd-9f5d-c51eba118943"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss') < 0.4 ):\n",
        "      print(\"\\nReached 60% accuracy so cancelling traning!\")\n",
        "      self.model.stop_traning = True\n",
        "\n",
        "# printing is okay but it is not stopping!!\n",
        "callbacks = myCallback()\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(traning_images, traning_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "traning_images = traning_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "          tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(traning_images, traning_labels, epochs=20, callbacks=[callbacks])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4767\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3594\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3239\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2993\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2780\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2644\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2506\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2394\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2292\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2202\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2109\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2036\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1982\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1892\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1860\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1756\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1730\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1654\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1624\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1563\n",
            "\n",
            "Reached 60% accuracy so cancelling traning!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f971be4c750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8dbAKamRdhx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}